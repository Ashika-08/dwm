{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOoS85DDJVZuMaCHl665euj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ashika-08/dwm/blob/main/dwmlab\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCEEi5ZZgI5_",
        "outputId": "29533ea9-2769-4b68-9b9e-8802fdd1c595"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Outlook': {'Overcast': 'Yes',\n",
            "             'Rain': {'Wind': {'Strong': 'No', 'Weak': 'Yes'}},\n",
            "             'Sunny': {'Humidity': {'High': 'No', 'Normal': 'Yes'}}}}\n"
          ]
        }
      ],
      "source": [
        "import csv\n",
        "import math\n",
        "import pprint\n",
        "from collections import defaultdict\n",
        "from itertools import chain, combinations\n",
        "\n",
        "# Data from the table\n",
        "data = [\n",
        "    {'Outlook': 'Sunny', 'Temperature': 'Hot', 'Humidity': 'High', 'Wind': 'Weak', 'PlayTennis': 'No'},\n",
        "    {'Outlook': 'Sunny', 'Temperature': 'Hot', 'Humidity': 'High', 'Wind': 'Strong', 'PlayTennis': 'No'},\n",
        "    {'Outlook': 'Overcast', 'Temperature': 'Hot', 'Humidity': 'High', 'Wind': 'Weak', 'PlayTennis': 'Yes'},\n",
        "    {'Outlook': 'Rain', 'Temperature': 'Mild', 'Humidity': 'High', 'Wind': 'Weak', 'PlayTennis': 'Yes'},\n",
        "    {'Outlook': 'Rain', 'Temperature': 'Cool', 'Humidity': 'Normal', 'Wind': 'Weak', 'PlayTennis': 'Yes'},\n",
        "    {'Outlook': 'Rain', 'Temperature': 'Cool', 'Humidity': 'Normal', 'Wind': 'Strong', 'PlayTennis': 'No'},\n",
        "    {'Outlook': 'Overcast', 'Temperature': 'Cool', 'Humidity': 'Normal', 'Wind': 'Strong', 'PlayTennis': 'Yes'},\n",
        "    {'Outlook': 'Sunny', 'Temperature': 'Mild', 'Humidity': 'High', 'Wind': 'Weak', 'PlayTennis': 'No'},\n",
        "    {'Outlook': 'Sunny', 'Temperature': 'Cool', 'Humidity': 'Normal', 'Wind': 'Weak', 'PlayTennis': 'Yes'},\n",
        "    {'Outlook': 'Rain', 'Temperature': 'Mild', 'Humidity': 'Normal', 'Wind': 'Weak', 'PlayTennis': 'Yes'},\n",
        "    {'Outlook': 'Sunny', 'Temperature': 'Mild', 'Humidity': 'Normal', 'Wind': 'Strong', 'PlayTennis': 'Yes'},\n",
        "    {'Outlook': 'Overcast', 'Temperature': 'Mild', 'Humidity': 'High', 'Wind': 'Strong', 'PlayTennis': 'Yes'},\n",
        "    {'Outlook': 'Overcast', 'Temperature': 'Hot', 'Humidity': 'Normal', 'Wind': 'Weak', 'PlayTennis': 'Yes'},\n",
        "    {'Outlook': 'Rain', 'Temperature': 'Mild', 'Humidity': 'High', 'Wind': 'Strong', 'PlayTennis': 'No'}\n",
        "]\n",
        "\n",
        "# Save the dataset as CSV\n",
        "csv_file = 'play_tennis.csv'\n",
        "csv_columns = data[0].keys()\n",
        "\n",
        "try:\n",
        "    with open(csv_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.DictWriter(csvfile, fieldnames=csv_columns)\n",
        "        writer.writeheader()\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "except IOError:\n",
        "    print(\"I/O error\")\n",
        "\n",
        "# Read the dataset from CSV\n",
        "def read_csv(file):\n",
        "    dataset = []\n",
        "    with open(file, mode='r') as csvfile:\n",
        "        csv_reader = csv.DictReader(csvfile)\n",
        "        for row in csv_reader:\n",
        "            dataset.append(row)\n",
        "    return dataset\n",
        "\n",
        "data = read_csv(csv_file)\n",
        "\n",
        "# Helper function to calculate entropy\n",
        "def entropy(s):\n",
        "    label_counts = defaultdict(int)\n",
        "    for entry in s:\n",
        "        label = entry['PlayTennis']\n",
        "        label_counts[label] += 1\n",
        "\n",
        "    total_entries = len(s)\n",
        "    ent = 0.0\n",
        "    for label in label_counts:\n",
        "        prob = label_counts[label] / total_entries\n",
        "        ent -= prob * math.log2(prob)\n",
        "    return ent\n",
        "\n",
        "# Helper function to calculate information gain\n",
        "def info_gain(s, attribute):\n",
        "    base_entropy = entropy(s)\n",
        "\n",
        "    subsets = defaultdict(list)\n",
        "    for entry in s:\n",
        "        key = entry[attribute]\n",
        "        subsets[key].append(entry)\n",
        "\n",
        "    total_entries = len(s)\n",
        "    subset_entropy = 0.0\n",
        "    for key in subsets:\n",
        "        prob = len(subsets[key]) / total_entries\n",
        "        subset_entropy += prob * entropy(subsets[key])\n",
        "\n",
        "    return base_entropy - subset_entropy\n",
        "\n",
        "# Function to choose the best attribute to split on\n",
        "def choose_best_attribute(s, attributes):\n",
        "    best_gain = 0.0\n",
        "    best_attr = None\n",
        "    for attribute in attributes:\n",
        "        gain = info_gain(s, attribute)\n",
        "        if gain > best_gain:\n",
        "            best_gain = gain\n",
        "            best_attr = attribute\n",
        "    return best_attr\n",
        "\n",
        "# Recursive function to build the decision tree\n",
        "def build_tree(s, attributes):\n",
        "    labels = [entry['PlayTennis'] for entry in s]\n",
        "    if labels.count(labels[0]) == len(labels):\n",
        "        return labels[0]\n",
        "\n",
        "    if not attributes:\n",
        "        return max(set(labels), key=labels.count)\n",
        "\n",
        "    best_attr = choose_best_attribute(s, attributes)\n",
        "\n",
        "    tree = {best_attr: {}}\n",
        "\n",
        "    unique_values = set(entry[best_attr] for entry in s)\n",
        "\n",
        "    remaining_attrs = [attr for attr in attributes if attr != best_attr]\n",
        "\n",
        "    for value in unique_values:\n",
        "        subset = [entry for entry in s if entry[best_attr] == value]\n",
        "        subtree = build_tree(subset, remaining_attrs)\n",
        "        tree[best_attr][value] = subtree\n",
        "\n",
        "    return tree\n",
        "\n",
        "# List of attributes\n",
        "attributes = ['Outlook', 'Temperature', 'Humidity', 'Wind']\n",
        "\n",
        "# Build the decision tree\n",
        "decision_tree = build_tree(data, attributes)\n",
        "\n",
        "# Print the decision tree\n",
        "pprint.pprint(decision_tree)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import random\n",
        "import math\n",
        "\n",
        "# Data from the table\n",
        "data = [\n",
        "    [1.0, 1.0],\n",
        "    [1.5, 2.0],\n",
        "    [3.0, 4.0],\n",
        "    [5.0, 7.0],\n",
        "    [3.5, 5.0],\n",
        "    [4.5, 5.0],\n",
        "    [3.5, 4.5]\n",
        "]\n",
        "\n",
        "# Save the dataset as CSV\n",
        "csv_file = 'kmeans_data.csv'\n",
        "\n",
        "try:\n",
        "    with open(csv_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['X', 'Y'])\n",
        "        for row in data:\n",
        "            writer.writerow(row)\n",
        "except IOError:\n",
        "    print(\"I/O error\")\n",
        "\n",
        "# Read the dataset from CSV\n",
        "def read_csv(file):\n",
        "    dataset = []\n",
        "    with open(file, mode='r') as csvfile:\n",
        "        csv_reader = csv.reader(csvfile)\n",
        "        next(csv_reader)  # Skip header\n",
        "        for row in csv_reader:\n",
        "            dataset.append([float(value) for value in row])\n",
        "    return dataset\n",
        "\n",
        "data = read_csv(csv_file)\n",
        "\n",
        "# Function to calculate Euclidean distance\n",
        "def euclidean_distance(p1, p2):\n",
        "    return math.sqrt(sum((x - y) ** 2 for x, y in zip(p1, p2)))\n",
        "\n",
        "# Function to assign clusters\n",
        "def assign_clusters(data, centroids):\n",
        "    clusters = {}\n",
        "    for point in data:\n",
        "        closest_centroid = min(centroids, key=lambda centroid: euclidean_distance(point, centroid))\n",
        "        if closest_centroid not in clusters:\n",
        "            clusters[closest_centroid] = []\n",
        "        clusters[closest_centroid].append(point)\n",
        "    return clusters\n",
        "\n",
        "# Function to update centroids\n",
        "def update_centroids(clusters):\n",
        "    new_centroids = []\n",
        "    for points in clusters.values():\n",
        "        new_centroid = [sum(dim) / len(points) for dim in zip(*points)]\n",
        "        new_centroids.append(tuple(new_centroid))\n",
        "    return new_centroids\n",
        "\n",
        "# K-means clustering function\n",
        "def kmeans(data, k, max_iterations=100):\n",
        "    # Randomly initialize centroids\n",
        "    centroids = random.sample(data, k)\n",
        "    centroids = [tuple(centroid) for centroid in centroids]\n",
        "\n",
        "    for _ in range(max_iterations):\n",
        "        clusters = assign_clusters(data, centroids)\n",
        "        new_centroids = update_centroids(clusters)\n",
        "\n",
        "        # Convergence check\n",
        "        if set(new_centroids) == set(centroids):\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return clusters, centroids\n",
        "\n",
        "# Number of clusters\n",
        "k = 2\n",
        "\n",
        "# Run K-means algorithm\n",
        "clusters, centroids = kmeans(data, k)\n",
        "\n",
        "# Print the results\n",
        "print(\"Clusters:\")\n",
        "for centroid, points in clusters.items():\n",
        "    print(f\"Centroid {centroid}: {points}\")\n",
        "\n",
        "print(\"\\nFinal Centroids:\")\n",
        "for centroid in centroids:\n",
        "    print(centroid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWkDkWNth4uH",
        "outputId": "cd973b51-6cea-4159-a4c9-b7c7e6c8295b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clusters:\n",
            "Centroid (1.25, 1.5): [[1.0, 1.0], [1.5, 2.0]]\n",
            "Centroid (3.9, 5.1): [[3.0, 4.0], [5.0, 7.0], [3.5, 5.0], [4.5, 5.0], [3.5, 4.5]]\n",
            "\n",
            "Final Centroids:\n",
            "(1.25, 1.5)\n",
            "(3.9, 5.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data points\n",
        "x = [0, 1, 2, 3, 4]\n",
        "y = [2, 3, 5, 4, 6]\n",
        "\n",
        "# Number of data points\n",
        "n = len(x)\n",
        "\n",
        "# Step 1: Calculate the mean of x and y\n",
        "mean_x = sum(x) / n\n",
        "mean_y = sum(y) / n\n",
        "\n",
        "# Step 2: Calculate the slope (a)\n",
        "numerator = sum((x[i] - mean_x) * (y[i] - mean_y) for i in range(n))\n",
        "denominator = sum((x[i] - mean_x) ** 2 for i in range(n))\n",
        "a = numerator / denominator\n",
        "\n",
        "# Step 3: Calculate the intercept (b)\n",
        "b = mean_y - a * mean_x\n",
        "\n",
        "# Linear regression line equation: y = ax + b\n",
        "print(f\"Linear regression line: y = {a}x + {b}\")\n",
        "\n",
        "# Step 4: Estimate the value of y when x = 10\n",
        "x_estimate = 10\n",
        "y_estimate = a * x_estimate + b\n",
        "print(f\"Estimated value of y when x = {x_estimate}: {y_estimate}\")\n",
        "\n",
        "# Step 5: Calculate the error (Sum of Squared Errors)\n",
        "sse = sum((y[i] - (a * x[i] + b)) ** 2 for i in range(n))\n",
        "print(f\"Sum of Squared Errors: {sse}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ou8x_Qn_iJGZ",
        "outputId": "fe26c3be-990f-42e0-bfa7-123cdac4d391"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear regression line: y = 0.9x + 2.2\n",
            "Estimated value of y when x = 10: 11.2\n",
            "Sum of Squared Errors: 1.9000000000000006\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import math\n",
        "\n",
        "# Points\n",
        "points = {\n",
        "    \"A1\": (2, 10),\n",
        "    \"A2\": (2, 5),\n",
        "    \"A3\": (8, 4),\n",
        "    \"A4\": (5, 8),\n",
        "    \"A5\": (7, 5),\n",
        "    \"A6\": (6, 4),\n",
        "    \"A7\": (1, 2),\n",
        "    \"A8\": (4, 9)\n",
        "}\n",
        "\n",
        "# Initial cluster centers\n",
        "centroids = {\n",
        "    \"C1\": (2, 10),\n",
        "    \"C2\": (5, 8),\n",
        "    \"C3\": (1, 2)\n",
        "}\n",
        "\n",
        "# Save the dataset as CSV\n",
        "csv_file = 'kmeans_points.csv'\n",
        "csv_centroids_file = 'kmeans_centroids.csv'\n",
        "\n",
        "# Save points to CSV\n",
        "try:\n",
        "    with open(csv_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['Point', 'X', 'Y'])\n",
        "        for point, coords in points.items():\n",
        "            writer.writerow([point, coords[0], coords[1]])\n",
        "except IOError:\n",
        "    print(\"I/O error while saving points\")\n",
        "\n",
        "# Save centroids to CSV\n",
        "try:\n",
        "    with open(csv_centroids_file, 'w', newline='') as csvfile:\n",
        "        writer = csv.writer(csvfile)\n",
        "        writer.writerow(['Centroid', 'X', 'Y'])\n",
        "        for centroid, coords in centroids.items():\n",
        "            writer.writerow([centroid, coords[0], coords[1]])\n",
        "except IOError:\n",
        "    print(\"I/O error while saving centroids\")\n",
        "\n",
        "# Read the dataset from CSV\n",
        "def read_csv(file):\n",
        "    dataset = {}\n",
        "    with open(file, mode='r') as csvfile:\n",
        "        csv_reader = csv.reader(csvfile)\n",
        "        next(csv_reader)  # Skip header\n",
        "        for row in csv_reader:\n",
        "            dataset[row[0]] = (float(row[1]), float(row[2]))\n",
        "    return dataset\n",
        "\n",
        "points = read_csv(csv_file)\n",
        "centroids = read_csv(csv_centroids_file)\n",
        "\n",
        "# Function to calculate Euclidean distance\n",
        "def euclidean_distance(p1, p2):\n",
        "    return math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)\n",
        "\n",
        "# Function to assign clusters\n",
        "def assign_clusters(points, centroids):\n",
        "    clusters = {key: [] for key in centroids}\n",
        "    for point_id, point in points.items():\n",
        "        closest_centroid = min(centroids, key=lambda c: euclidean_distance(point, centroids[c]))\n",
        "        clusters[closest_centroid].append(point)\n",
        "    return clusters\n",
        "\n",
        "# Function to update centroids\n",
        "def update_centroids(clusters):\n",
        "    new_centroids = {}\n",
        "    for cluster_id, cluster_points in clusters.items():\n",
        "        if cluster_points:\n",
        "            mean_x = sum(p[0] for p in cluster_points) / len(cluster_points)\n",
        "            mean_y = sum(p[1] for p in cluster_points) / len(cluster_points)\n",
        "            new_centroids[cluster_id] = (mean_x, mean_y)\n",
        "        else:\n",
        "            new_centroids[cluster_id] = centroids[cluster_id]  # Keep the old centroid if no points assigned\n",
        "    return new_centroids\n",
        "\n",
        "# K-means clustering function\n",
        "def kmeans(points, centroids, max_iterations=100):\n",
        "    for _ in range(max_iterations):\n",
        "        clusters = assign_clusters(points, centroids)\n",
        "        new_centroids = update_centroids(clusters)\n",
        "\n",
        "        # Convergence check\n",
        "        if new_centroids == centroids:\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return clusters, centroids\n",
        "\n",
        "# Run K-means algorithm\n",
        "clusters, final_centroids = kmeans(points, centroids)\n",
        "\n",
        "# Print the results\n",
        "print(\"Clusters:\")\n",
        "for cluster_id, cluster_points in clusters.items():\n",
        "    print(f\"{cluster_id}: {cluster_points}\")\n",
        "\n",
        "print(\"\\nFinal Centroids:\")\n",
        "for centroid_id, centroid in final_centroids.items():\n",
        "    print(f\"{centroid_id}: {centroid}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDOB9D5Qitu5",
        "outputId": "782421ce-6b1c-42cc-9191-2073e1b03f6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clusters:\n",
            "C1: [(2.0, 10.0), (5.0, 8.0), (4.0, 9.0)]\n",
            "C2: [(8.0, 4.0), (7.0, 5.0), (6.0, 4.0)]\n",
            "C3: [(2.0, 5.0), (1.0, 2.0)]\n",
            "\n",
            "Final Centroids:\n",
            "C1: (3.6666666666666665, 9.0)\n",
            "C2: (7.0, 4.333333333333333)\n",
            "C3: (1.5, 3.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from datetime import datetime\n",
        "\n",
        "# Raw data\n",
        "data = [\n",
        "    [1, 21, \"1L\", \"Male\", \"31.05.1992\", \"No\"],\n",
        "    [2, 35, \"100000\", \"Male\", \"10-05-2002\", \"No\"],\n",
        "    [3, 26, \"45000\", \"Male\", \"Aug 5, 2000\", \"Yes\"],\n",
        "    [4, 45, \"\", \"Male\", \"\", \"Yes\"],\n",
        "    [5, 67, \"10000\", \"Female\", \"31.03.1986\", \"Yes\"],\n",
        "    [6, \"\", \"10000\", \"Female\", \"10/5/1987\", \"No\"],\n",
        "    [7, 32, \"5$\", \"Female\", \"31.05.1992\", \"Yes\"],\n",
        "    [8, 31, \"5 Dollars\", \"Male\", \"10-05-2002\", \"No\"],\n",
        "    [9, \"\", \"10000\", \"Female\", \"Aug 5, 2000\", \"Yes\"],\n",
        "    [10, 42, \"15000\", \"Female\", \"Sep 12'2000\", \"Yes\"],\n",
        "    [11, \"\", \"25000\", \"Female\", \"31.03.1986\", \"Yes\"],\n",
        "    [12, 32, \"35000\", \"Male\", \"10/5/1987\", \"Yes\"],\n",
        "    [13, 35, \"150000\", \"Female\", \"Sep 12'2000\", \"Yes\"],\n",
        "    [14, 35, \"35000\", \"Male\", \"31.03.1986\", \"No\"],\n",
        "]\n",
        "\n",
        "# Function to convert various income formats to a standardized numeric format\n",
        "def standardize_income(income):\n",
        "    if 'L' in income:\n",
        "        return 100000  # Assuming 1L is 100000\n",
        "    income = re.sub(r'[^\\d]', '', income)\n",
        "    return int(income) if income else 0\n",
        "\n",
        "# Function to standardize date format to YYYY-MM-DD\n",
        "def standardize_date(dob):\n",
        "    for fmt in ('%d.%m.%Y', '%d-%m-%Y', '%b %d, %Y', '%b %d\\'%Y', '%m/%d/%Y'):\n",
        "        try:\n",
        "            return datetime.strptime(dob, fmt).strftime('%Y-%m-%d')\n",
        "        except ValueError:\n",
        "            continue\n",
        "    return None  # Return None if the date format is unrecognized\n",
        "\n",
        "# Extract ages and incomes for statistical calculation\n",
        "ages = [row[1] for row in data if row[1] != \"\"]\n",
        "incomes = [standardize_income(row[2]) for row in data if row[2] != \"\"]\n",
        "\n",
        "# Calculate mean and median for Age and Income\n",
        "mean_age = sum(ages) / len(ages)\n",
        "mean_income = sum(incomes) / len(incomes)\n",
        "median_age = sorted(ages)[len(ages) // 2]\n",
        "median_income = sorted(incomes)[len(incomes) // 2]\n",
        "\n",
        "# Fill missing Age with mean value\n",
        "for row in data:\n",
        "    if row[1] == \"\":\n",
        "        row[1] = round(mean_age)\n",
        "    row[2] = standardize_income(row[2])\n",
        "    row[4] = standardize_date(row[4]) if row[4] else None\n",
        "\n",
        "# Calculate the proportion of people who buy\n",
        "buy_count = sum(1 for row in data if row[5] == \"Yes\")\n",
        "total_count = len(data)\n",
        "buy_proportion = buy_count / total_count\n",
        "\n",
        "# Output the cleaned data and statistical measures\n",
        "print(\"Cleaned Data:\")\n",
        "for row in data:\n",
        "    print(row)\n",
        "\n",
        "print(\"\\nStatistical Measures:\")\n",
        "print(f\"Mean Age: {mean_age:.2f}\")\n",
        "print(f\"Mean Income: {mean_income:.2f}\")\n",
        "print(f\"Median Age: {median_age}\")\n",
        "print(f\"Median Income: {median_income}\")\n",
        "print(f\"Proportion of Buys: {buy_proportion:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v-HKGGUmkHpy",
        "outputId": "e2e40a4a-163c-4806-d294-42fbd3ca4b1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Data:\n",
            "[1, 21, 100000, 'Male', '1992-05-31', 'No']\n",
            "[2, 35, 100000, 'Male', '2002-05-10', 'No']\n",
            "[3, 26, 45000, 'Male', '2000-08-05', 'Yes']\n",
            "[4, 45, 0, 'Male', None, 'Yes']\n",
            "[5, 67, 10000, 'Female', '1986-03-31', 'Yes']\n",
            "[6, 36, 10000, 'Female', '1987-10-05', 'No']\n",
            "[7, 32, 5, 'Female', '1992-05-31', 'Yes']\n",
            "[8, 31, 5, 'Male', '2002-05-10', 'No']\n",
            "[9, 36, 10000, 'Female', '2000-08-05', 'Yes']\n",
            "[10, 42, 15000, 'Female', '2000-09-12', 'Yes']\n",
            "[11, 36, 25000, 'Female', '1986-03-31', 'Yes']\n",
            "[12, 32, 35000, 'Male', '1987-10-05', 'Yes']\n",
            "[13, 35, 150000, 'Female', '2000-09-12', 'Yes']\n",
            "[14, 35, 35000, 'Male', '1986-03-31', 'No']\n",
            "\n",
            "Statistical Measures:\n",
            "Mean Age: 36.45\n",
            "Mean Income: 41154.62\n",
            "Median Age: 35\n",
            "Median Income: 25000\n",
            "Proportion of Buys: 0.64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "\n",
        "# Points\n",
        "points = {\n",
        "    \"A\": (2, 2),\n",
        "    \"B\": (3, 2),\n",
        "    \"C\": (1, 1),\n",
        "    \"D\": (3, 1),\n",
        "    \"E\": (1.5, 0.5)\n",
        "}\n",
        "\n",
        "# Initial cluster centers\n",
        "centroids = {\n",
        "    \"Cluster1\": (2, 2),\n",
        "    \"Cluster2\": (1, 1)\n",
        "}\n",
        "\n",
        "# Function to calculate Euclidean distance\n",
        "def euclidean_distance(p1, p2):\n",
        "    return math.sqrt((p1[0] - p2[0]) ** 2 + (p1[1] - p2[1]) ** 2)\n",
        "\n",
        "# Function to assign clusters\n",
        "def assign_clusters(points, centroids):\n",
        "    clusters = {key: [] for key in centroids}\n",
        "    for point_id, point in points.items():\n",
        "        closest_centroid = min(centroids, key=lambda c: euclidean_distance(point, centroids[c]))\n",
        "        clusters[closest_centroid].append(point)\n",
        "    return clusters\n",
        "\n",
        "# Function to update centroids\n",
        "def update_centroids(clusters):\n",
        "    new_centroids = {}\n",
        "    for cluster_id, cluster_points in clusters.items():\n",
        "        mean_x = sum(p[0] for p in cluster_points) / len(cluster_points)\n",
        "        mean_y = sum(p[1] for p in cluster_points) / len(cluster_points)\n",
        "        new_centroids[cluster_id] = (mean_x, mean_y)\n",
        "    return new_centroids\n",
        "\n",
        "# K-means clustering function\n",
        "def kmeans(points, centroids, max_iterations=100):\n",
        "    for _ in range(max_iterations):\n",
        "        clusters = assign_clusters(points, centroids)\n",
        "        new_centroids = update_centroids(clusters)\n",
        "\n",
        "        # Convergence check\n",
        "        if new_centroids == centroids:\n",
        "            break\n",
        "        centroids = new_centroids\n",
        "\n",
        "    return clusters, centroids\n",
        "\n",
        "# Run K-means algorithm\n",
        "clusters, final_centroids = kmeans(points, centroids)\n",
        "\n",
        "# Print the results\n",
        "print(\"Clusters:\")\n",
        "for cluster_id, cluster_points in clusters.items():\n",
        "    print(f\"{cluster_id}: {cluster_points}\")\n",
        "\n",
        "print(\"\\nFinal Centroids:\")\n",
        "for centroid_id, centroid in final_centroids.items():\n",
        "    print(f\"{centroid_id}: {centroid}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pqDTNoxznjEM",
        "outputId": "e176f60c-6593-4a87-9b98-831b7af3320c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Clusters:\n",
            "Cluster1: [(2, 2), (3, 2), (3, 1)]\n",
            "Cluster2: [(1, 1), (1.5, 0.5)]\n",
            "\n",
            "Final Centroids:\n",
            "Cluster1: (2.6666666666666665, 1.6666666666666667)\n",
            "Cluster2: (1.25, 0.75)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import itertools\n",
        "\n",
        "# Data creation\n",
        "data = {'tid': ['T1', 'T2', 'T3', 'T4', 'T5', 'T6'],\n",
        "        'items': [['HotDogs', 'Buns', 'Ketchup'],\n",
        "                  ['HotDogs', 'Buns'],\n",
        "                  ['HotDogs', 'Coke', 'Chips'],\n",
        "                  ['Chips', 'Coke'],\n",
        "                  ['Chips', 'Ketchup'],\n",
        "                  ['HotDogs', 'Coke', 'Chips']]}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Creating the basket (one-hot encoded DataFrame)\n",
        "basket = pd.DataFrame(df['items'].tolist(), index=df['tid']).stack().reset_index(level=1, drop=True).reset_index()\n",
        "basket.columns = ['tid', 'items']\n",
        "basket = pd.crosstab(basket['tid'], basket['items'])\n",
        "\n",
        "# Encoding function\n",
        "def encode_units(x):\n",
        "    return 1 if x >= 1 else 0\n",
        "\n",
        "basket_sets = basket.applymap(encode_units)\n",
        "\n",
        "# Function to generate frequent itemsets\n",
        "def apriori_manual(df, min_support=0.3334):\n",
        "    itemset_support = {}\n",
        "    num_transactions = len(df)\n",
        "    items = df.columns\n",
        "\n",
        "    def get_support(itemset):\n",
        "        mask = df[list(itemset)].all(axis=1)\n",
        "        return mask.sum() / num_transactions\n",
        "\n",
        "    # Generate frequent 1-itemsets\n",
        "    for item in items:\n",
        "        support = get_support([item])\n",
        "        if support >= min_support:\n",
        "            itemset_support[frozenset([item])] = support\n",
        "\n",
        "    current_itemsets = list(itemset_support.keys())\n",
        "    k = 2\n",
        "\n",
        "    while current_itemsets:\n",
        "        new_itemsets = list(itertools.combinations(set(itertools.chain.from_iterable(current_itemsets)), k))\n",
        "        new_itemset_support = {}\n",
        "\n",
        "        for itemset in new_itemsets:\n",
        "            support = get_support(itemset)\n",
        "            if support >= min_support:\n",
        "                new_itemset_support[frozenset(itemset)] = support\n",
        "\n",
        "        itemset_support.update(new_itemset_support)\n",
        "        current_itemsets = new_itemset_support.keys()\n",
        "        k += 1\n",
        "\n",
        "    frequent_itemsets = pd.DataFrame(\n",
        "        [(list(itemset), support) for itemset, support in itemset_support.items()],\n",
        "        columns=['itemsets', 'support']\n",
        "    )\n",
        "\n",
        "    return frequent_itemsets\n",
        "\n",
        "frequent_itemsets = apriori_manual(basket_sets)\n",
        "\n",
        "# Function to generate association rules\n",
        "def generate_association_rules(frequent_itemsets, min_confidence=0.6):\n",
        "    rules = []\n",
        "    itemsets = frequent_itemsets['itemsets'].tolist()\n",
        "    supports = dict(zip(map(frozenset, frequent_itemsets['itemsets']), frequent_itemsets['support']))\n",
        "\n",
        "    for itemset in itemsets:\n",
        "        if len(itemset) > 1:\n",
        "            for subset in itertools.chain(*[itertools.combinations(itemset, r) for r in range(1, len(itemset))]):\n",
        "                antecedent = frozenset(subset)\n",
        "                consequent = frozenset(itemset) - antecedent\n",
        "                if supports[frozenset(itemset)] / supports[antecedent] >= min_confidence:\n",
        "                    rules.append({\n",
        "                        'antecedent': list(antecedent),\n",
        "                        'consequent': list(consequent),\n",
        "                        'antecedent support': supports[antecedent],\n",
        "                        'consequent support': supports[consequent],\n",
        "                        'support': supports[frozenset(itemset)],\n",
        "                        'confidence': supports[frozenset(itemset)] / supports[antecedent],\n",
        "                        'lift': supports[frozenset(itemset)] / (supports[antecedent] * supports[consequent])\n",
        "                    })\n",
        "\n",
        "    return pd.DataFrame(rules)\n",
        "\n",
        "rules = generate_association_rules(frequent_itemsets)\n",
        "\n",
        "print(\"Frequent itemsets:\")\n",
        "print(frequent_itemsets)\n",
        "print(\"\\nAssociation Rules:\")\n",
        "print(rules.sort_values(by='confidence', ascending=False))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BCa7ntroKbE",
        "outputId": "c53e041c-553d-4a46-89cf-2b5a52d72fd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent itemsets:\n",
            "        itemsets   support\n",
            "0        [Chips]  0.666667\n",
            "1         [Coke]  0.500000\n",
            "2      [HotDogs]  0.666667\n",
            "3  [Coke, Chips]  0.500000\n",
            "\n",
            "Association Rules:\n",
            "  antecedent consequent  antecedent support  consequent support  support  \\\n",
            "0     [Coke]    [Chips]            0.500000            0.666667      0.5   \n",
            "1    [Chips]     [Coke]            0.666667            0.500000      0.5   \n",
            "\n",
            "   confidence  lift  \n",
            "0        1.00   1.5  \n",
            "1        0.75   1.5  \n"
          ]
        }
      ]
    }
  ]
}